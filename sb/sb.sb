# NOTE early dispatch makes more rules but less `if`s, see also methodology.md

# pre-process: replace tabs with '  ', replace "\r\n" with "\n"

# we need an ST representation that can be restored to code, so:
# - some tokens are for css styling only
# - eol is a token which may contain comment and space before comment
# - spaces before a action/eql-sign should be kept
# - spaces in regexp gets special treatment

# for bootstrap, this file uses only the minimal subset of spellbreak
# - calls with optional params are filled with concrete params
# - no use of `\u`, `\x` and `{n}` in regexp
# - no use nested regexp
# - special chars inside `[]` are escaped
# - no use if/infix in callbacks
# - all `#` in regexp or string are escaped
# - all structs are defined in one-line
# - no lookahead for PEG

# NOTE immutable data structure is vital to PEG callbacks
#      but the most efficient way to impl queue is just reverse the list

# lexer impl
# the objects $0, $1, $2, ... are in fact un-named tokens,
# so :token action is add a type to it, and then put it into stream
# a second :token action using the same object, will duplicate it

lex Main[
  end /\z/ { :peg "Main" }

  /pattern\b/ { :token "kw.pattern" } /\ +(@\w+)/    { :token "name.pattern" 1 } /\ *=\ /
  /var\b/     { :token "kw.var" } /\ +(\$[a-z]\w*)/  { :token "name.var.global" 1 }
  /struct\b/  { :token "kw.struct" } /\ +([A-Z]\w*)/ { :token "name.struct" 1 } StructIns
  /lex\b/     { :token "kw.lex" } /\ +(\*?[A-Z]\w*)/ { :token "name.context" 1 } Lex
  /peg\b/     { :token "kw.peg" } /\ +([A-Z]\w*)/    { :token "name.context" 1 } Peg
  # TODO cfg, tag, ...

  String
  Regexp

  *Spaces
]

struct Main[ins]
struct PatternIns[name, pattern]
struct StructIns[name, args]
struct VarDecl[var_name]
struct Lex[context, rules]
struct Peg[context, rules]
peg Main[
  Main : Line* { Main[$1] }

  Line : space.eol { } / Ins { $1 }

  Ins : kw.pattern name.pattern space.pre-eq op.eq Pattern { PatternIns[$2, $5] }
      / kw.var name.var.global { VarDecl[$2] }
      / kw.struct name.struct name.arg* { StructIns[$2, $3] }
      / kw.lex name.context Lex { Lex[$2, $3] }
      / kw.peg name.context Peg { Peg[$2, $3] }

  Pattern : String { $1 } / Regexp { $1 }
]

lex StructIns[
  begin "[" { }
  end "]" { }
  /([a-z]\w*)\s*,/ { :token "name.arg" 1 }
  /[a-z]\w*/       { :token "name.arg" }
  *Spaces
]

lex Lex[
  begin "[" { :token "begin.lex" }
  end "]" { :token "end.lex", :peg "Lex" }

  Regexp
  String
  Callback
  /begin\b/    { :token "kw.begin" } # TODO new syntax: `someword` for keyword matching
  /end\b/      { :token "kw.end" }
  /\*[A-Z]\w*/ { :token "name.context.partial" }
  /[A-Z]\w*/   { :token "name.context" }
  /[a-z]\w*/   { :token "name.var" }
  /$[a-z]\w*/  { :token "name.var.global" }

  *Spaces
]

struct RefPartialContext[name]
struct RefContext[name]
struct SeqLexRules[rules]
struct BeginCallback[first_cb, rules]
struct EndCallback[first_cb, rules]
struct LexRule[pattern, code]
struct VarRef[var_name]
struct GlobalVarRef[name]
peg Lex[
  Lex : begin.lex RuleLine* end.lex { $2 }
  RuleLine : name.context.partial { RefPartialContext[$1] }
           / name.context { RefContext[$1] }
           / Rule+ { SeqLexRules[$1] }
           / kw.begin Callback? Rule+ { BeginCallback[$2, $3] }
           / kw.end Callback Rule+ { EndCallback[$2, $3] }
           / space.eol { }
  Rule : Pattern space.pre-callback* Callback? { LexRule[$1, $3] }
  Pattern : String { $1 }
          / Regexp { $1 }
          / name.var { VarRef[$1] }
          / name.var.global { GlobalVarRef[$1] }
]

lex Peg[
  begin "[" { :token "begin.peg" }
  end "]" { :token "end.peg", peg "Peg" }

  "EPSILON" { :token "name.rule.epsilon" }
  /[A-Z]\w*(\.\w+)*/  { :token "name.rule" }
  /[a-z]\w*(\-\w+)*(\.\w+(\-\w+)*)*/  { :token "name.token" }

  ":"                 { :token "op.def" }
  "?"                 { :token "op.maybe" }
  "+"                 { :token "op.plus" }
  "*"                 { :token "op.star" }
  /[\/][\*\?\+]?/     { :token "op.branch" }
  /\/$\w+/            { :token "op.branch" }
  "&"                 { :token "op.lookahead" }
  "!"                 { :token "op.neg-lookahead" }

  Callback

  *Spaces
]

struct PegRule[name, body] # body = SeqRule / Branch
struct Branch[op, lhs, rhs_terms, code]
struct SeqRule[terms, code]
struct TermMaybe[unit]
struct TermStar[unit]
struct TermPlus[unit]
struct Term[unit]
struct Lookahead[unit]
struct NegLoookahead[unit]
struct EpsilonRule[]
struct RefRule[name]
peg Peg[
  Peg : begin.peg Rule* end.peg { $2 }
  Rule : name.rule op.def space.eol? RuleBody space.eol { PegRule[$1, $4] }
       / space.eol { }
  RuleBody : SeqRule { $1 }
           /* space.eol? op.branch Term* PureCallback? { Branch[$3, $1, $4, $5] }
  SeqRule : Term+ PureCallback? { SeqRule[$1, $2] }
  Term : Unit op.maybe         { TermMaybe[$1] }
       / Unit op.star          { TermStar[$1] }
       / Unit op.plus          { TermPlus[$1] }
       / Unit                  { Term[$1] }
       / op.lookahead Unit     { Lookahead[$2] }
       / op.neg-lookahead Unit { NegLoookahead[$2] }
  Unit : name.token { $1 }
       / name.rule.epsilon { EpsilonRule[] }
       / name.rule  { RefRule[$1] }
]

# no side effects
lex PureCallback[
  begin "{" { :token "begin.code" }
  end "}" { :token "end.code", :peg "Callback" }

  String
  /\$-?\d+/  { :token "name.var.capture" }
  /.\w+/     { :token "name.method" } # todo
  /[A-Z]\w*/ { :token "name.type" }
  /if\b/     { :token "kw.if" }
  /else\n/   { :token "kw.else" }
  /end\b/    { :token "kw.end" }
  /nil\b/    { :token "lit.nil" 0 nil }
  /true\n/   { :token "lit.true" 0 true }
  /false\n/  { :token "lit.const" 0 false }
  /-?\d+/    { :token "lit.int" 0 :parse_int 0 }

  /&&|\|\|/         { :token "op.infix.logic" }
  />|<|>=|<=|==|!=/ { :token "op.infix.compare" }
  /\+|-|\^|&|\|/    { :token "op.infix.additive" }
  /\*\*|\*|\/|%|@/  { :token "op.infix.multitive" } # TODO ** should be separated for right-assoc
  /(\[)\s*(\*)/ { :token "begin.list" 1, :token "op.prefix.splat" 2 }
  "[" { :token "begin.list" }
  "]" { :token "end.list" }
  "(" { :token "begin.paren" }
  ")" { :token "end.paren" }
  "!" { :token "op.prefix" }
  /(,)\s*(\*)/ { :token "space.eol" 1, :token "op.prefix.splat" 2 }
  /[,\n]/ { :token "space.eol" }

  /\#[^\n]*/   { :style "comment" }
  /\ +(?=\=)/ { :token "space.pre-eq" }
  /\ +/ { }
]

lex Callback[
  *PureCallback
  /var\b/      { :token "kw.var" }
  /\$[a-z]\w*/ { :token "name.var.global" }
  /[a-z]\w*/   { :token "name.var" }
  /:[\w+\-*\/^&|<>=!%@]+/ { :token "name.func" }
  "=" { :token "op.eq" }
]

# defined above: VarDecl VarRef
struct Callback[stmts] # stmts reversed
struct InfixLogic[lhs, op, rhs]
struct Call[func_name, argv] # argv reversed
struct Capture[var_name]
struct CreateNode[ty, elems] # elems reversed
struct CreateList[elems] # elems reversed
struct Assign[var_name, expr]
struct SplatEntry[expr]
struct If[expr, true_lines, false_lines] # lines reversed
peg Callback[
  Callback : begin.code Stmts end.code { Callback[$2] }
  Stmts : Expr Stmts { [$1, *$2] }
        / kw.var name.var Stmts { VarDecl[$2] }
        / space.eol Stmts { $2 }
        / EPSILON { }
  Expr : Infix.Logic { $1 }

  Infix.Logic : Infix.Compare { $1 }
              /* op.infix.logic Infix.Compare { InfixLogic[$1, $2, $3] }

  Infix.Compare : Infix.Additive { $1 }
                /* op.infix.compare Infix.Additive { Call[$2, [$3, $1]] }

  Infix.Additive : Infix.Multitive { $1 }
                 /* op.infix.additive Infix.Multitive { Call[$2, [$3, $1]] }

  Infix.Multitive : Unit { $1 }
                  /* op.infix.multitive Unit { Call[$2, [$3, $1]] }

  Unit : begin.paren Lines end.paren { $2 }
       / op.prefix Unit { Call[$1, [$2]] }
       / lit.int   { $1 }
       / lit.true  { $1 }
       / lit.false { $1 }
       / lit.nil   { $1 }
       / String    { $1 }
       / name.var.capture { Capture[$1] }
       / name.type begin.list Entries end.list { CreateNode[$1, $3] }
       / begin.list Entries end.list { CreateList[$2] }
       / name.func Expr* { Call[$1, $2] }
       / name.var space.pre-eq op.eq Expr { Assign[$1, $4] }
       / name.var { VarRef[$1] }
       / name.var.global { VarRef[$1] }
       / If { $1 }

  Entries : Expr Entries { [$1, *$2] }
          / op.prefix.splat Expr Entries { [SplatEntry[$2], *$3] }
          / space.eol Entries { $2 }
          / EPSILON { }
  Lines : Expr Lines { [$1, *$2] }
        / space.eol Lines { $2 }
        / EPSILON { }
  If : kw.if Expr space.eol Lines If.Else { If[$2, $4, $5] }
  # type: List / If
  If.Else : kw.end { }
          / kw.else Lines kw.end { $2 }
          / kw.else kw.end { }
          / kw.else If { $2 }
]

# TODO use vtoken instead of token to optimize parsing?
lex String[
  begin /"/ { var buf, buf = "", :token "begin.string" }
  end /"/ { :token "end.string", :yield buf }

  /\\x(\h\h)/     { :token "char.hex",       buf = :concat_char buf :char_hex 1 }
  /\\u\{(\h+)\}/  { :token "char.ux",        buf = :concat_char buf :char_hex 1 }
  /\\u(\h\h\h\h)/ { :token "char.u4",        buf = :concat_char buf :char_hex 1 }
  /\\([abftnr])/  { :token "char.escape.sp", buf = :concat_char buf :char_escape_sp 1 }
  /\\([^\n])/     { :token "char.escape",    buf = :concat_char buf :char_no_escape 1 }
  /./             { :token "char",           buf = :concat_char buf :char_no_escape 0 }
]

lex Regexp[
  begin "/" { :token "begin.regexp" }
  end "/" { :token "end.regexp", :peg "Regexp" }

  /\^|\$|\\[bBaAzZ]/ { :token "anchor" }

  /\\[dDwWhHsS]|\./    { :token "char-group.predef" }
  /\\p\{[A-Z][a-z]*\}/ { :token "unicode-char-class" }
  RegexpEscape
  *RegexpQuantifier

  "|" { :token "op.branch" }

  "[^" { :token "begin.char-group" 0 false }
  "["  { :token "begin.char-group" 0 true }
  "]"  { :token "end.char-group" }
  "-"  { :token "op.minus" 0 :char_no_escape 0 }

  /\{[A-Z]\w*\}/    { :token "interpolate.predef" }

  "(?i)"               { :token "flag.case-insensitive" 0 true }
  "(?I)"               { :token "flag.case-sensitive" 0 false }
  /\(\?e:\w+(-\w+)?\)/ { :token "flag.encoding" }

  /(\()(\?:|\?=|\?!|\?<=|\?<!|\?>)?/ {
    :token "begin.group" 1
    :token "group.special" 2
  }
  ")" { :token "end.group" }

  /\s+/ {} # only useful in pretty print
  /[^\n\s]/ { :token "char" 0 :char_no_escape 0 }
]

struct Regexp[reg]
struct Seq[seq]
struct PredefAnchor[anchor]
struct Flag[flag]
struct Quantified[unit, quantifier]
struct QuantifiedRange[unit, from, to_maybe, kind]
struct PredefInterpolate[pattern_name]
struct Group[special, branches]
struct CharGroupPredef[tok]
struct UnicodeCharClass[name]
struct BracketCharGroup[beg_tok, char_classes]
struct CharRange[from, to]
peg Regexp[
  Regexp : begin.regexp Branches end.regexp { Regexp[$2] }
  Branches : Seq { [$1] } /* op.branch Seq { [$3, *$1] }
  Seq : SeqUnit* { Seq[$1] }
  SeqUnit : anchor { PredefAnchor[$1] }
          / flag.case-insensitive { Flag[$1] }
          / flag.case-sensitive { Flag[$1] }
          / flag.encoding { Flag[$1] }
          / Unit quantifier { Quantified[$1, $2] }
          / Unit begin.quantifier quantifier.range.from quantifier.range.to? end.quantifier quantifier.kind { QuantifiedRange[$1, $3, $4, $6] }
          / Unit { $1 }
  Unit : SingleChar { $1 }
       / CharGroup  { $1 }
       / Group { $1 }
       / interpolate.predef { PredefInterpolate[$1] }
  SingleChar : RegexpEscape { $1 }
             / op.minus     { $1 }
             / char         { $1 }
  Group : begin.group group.special Branches end.group { Group[$2, $3] }

  CharGroup : char-group.predef  { CharGroupPredef[$1] }
            / unicode-char-class { UnicodeCharClass[$1] }
            / begin.char-group CharClass+ end.char-group { BracketCharGroup[$1, $2] }
  CharClass : CharGroup { $1 }
            / SingleChar op.minus SingleChar { CharRange[$1, $3] }
            / SingleChar { CharRange[$1, $1] }
]

lex RegexpEscape[
  begin "\\" { :token "char.escape" }
  end /x(\h\h)/     { :token "char.escape", :yield :char_hex 1 }
  end /u\{(\h+)\}/  { :token "char.escape", :yield :char_hex 1 }
  end /u(\h\h\h\h)/ { :token "char.escape", :yield :char_hex 1 }
  end /[abftnr]/    { :token "char.escape", :yield :char_escape_sp 0 }
  end /[^\n]/       { :token "char.escape", :yield :char_no_escape 0 }
]

lex *RegexpQuantifier[
  /\?\+ | \?\? | \? | \+\+ | \+\? | \+ | \*\+ | \*\? | \*/ {
    :token "quantifier"
  }

  /(\{) \s* (\d+) \s* (\}) ([\+\?]?)/ {
    :token "begin.quantifier" 1
    :token "quantifier.range.from" 2
    :token "end.quantifier" 3
    :token "quantifier.kind" 4
  }

  /(\{) \s* (\d+) \s*,\s* (\d*) \s* (\}) ([\+\?]?)/ {
    :token "begin.quantifier" 1
    :token "quantifier.range.from" 2
    :token "quantifier.range.to" 3
    :token "end.quantifier" 4
    :token "quantifier.kind" 5
  }
]

lex *Spaces[
  /\ +(?=\{)/   { :token "space.pre-callback" }
  /\ +(?=\=)/   { :token "space.pre-eq" }

  /\ *(\#[^\n]*)?(\n|\z)/ { :token "space.eol", :style "comment" 1 }

  /\ +/ { } # ignore
]
